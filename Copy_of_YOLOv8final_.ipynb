{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOel+M+j7mqeGbbAgKj0XTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeMANSC/GenAI/blob/main/Copy_of_YOLOv8final_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLO V8 model\n",
        "By HEMANT SINGH\n"
      ],
      "metadata": {
        "id": "JiyI_2p3CeWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GITHUB LINK\n"
      ],
      "metadata": {
        "id": "3S0EjmQ7CoxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bw2A29yrA-D5",
        "outputId": "8984f9c9-80c9-4179-c3d6-136d84b6d8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.70)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function useCam(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      document.body.appendChild(div);\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'None';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "      \n",
              "      display_size = 500;\n",
              "      const src_canvas = document.createElement('canvas');\n",
              "      src_canvas.width  = display_size;\n",
              "      src_canvas.height = display_size * video.videoHeight / video.videoWidth;\n",
              "      const src_canvasCtx = src_canvas.getContext('2d');\n",
              "      src_canvasCtx.translate(src_canvas.width, 0);\n",
              "      src_canvasCtx.scale(-1, 1);\n",
              "      div.appendChild(src_canvas);\n",
              "\n",
              "      const dst_canvas = document.createElement('canvas');\n",
              "      dst_canvas.width  = src_canvas.width;\n",
              "      dst_canvas.height = src_canvas.height;\n",
              "      const dst_canvasCtx = dst_canvas.getContext('2d');\n",
              "      div.appendChild(dst_canvas);\n",
              "      \n",
              "      const btn_div = document.createElement('div');\n",
              "      document.body.appendChild(btn_div);\n",
              "      const exit_btn = document.createElement('button');\n",
              "      exit_btn.textContent = 'Exit';\n",
              "      var exit_flg = true;\n",
              "      exit_btn.onclick = function() { exit_flg = false };\n",
              "      btn_div.appendChild(exit_btn);\n",
              "\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "      \n",
              "      var send_flg = false;\n",
              "      async function _canvasUpdate() {\n",
              "        src_canvasCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight, 0, 0, src_canvas.width, src_canvas.height);     \n",
              "        if (send_flg == false) {\n",
              "            send_flg = true;\n",
              "            const img = src_canvas.toDataURL('image/jpeg', quality);\n",
              "            const result = google.colab.kernel.invokeFunction('notebook.run', [img], {});\n",
              "            result.then(function(value) {\n",
              "                parse = JSON.parse(JSON.stringify(value))['data'];\n",
              "                parse = JSON.parse(JSON.stringify(parse))['application/json'];\n",
              "                parse = JSON.parse(JSON.stringify(parse))['img_str'];\n",
              "                var image = new Image();\n",
              "                image.src = parse;\n",
              "                image.onload = function() { dst_canvasCtx.drawImage(image, 0, 0); };\n",
              "                send_flg = false;\n",
              "            });\n",
              "        }\n",
              "        if (exit_flg) {\n",
              "            requestAnimationFrame(_canvasUpdate);   \n",
              "        } else {\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "        }\n",
              "      }\n",
              "      _canvasUpdate();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 68.2ms\n",
            "Speed: 25.9ms preprocess, 68.2ms inference, 512.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 3.4ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.9ms\n",
            "Speed: 14.1ms preprocess, 17.9ms inference, 14.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cat, 35.3ms\n",
            "Speed: 4.1ms preprocess, 35.3ms inference, 16.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 1 cell phone, 11.9ms\n",
            "Speed: 4.1ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 12.0ms\n",
            "Speed: 4.1ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 wine glass, 1 cell phone, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 wine glass, 7.2ms\n",
            "Speed: 2.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 7.3ms\n",
            "Speed: 2.7ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 10.1ms\n",
            "Speed: 4.6ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 1 cell phone, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 1 cell phone, 7.3ms\n",
            "Speed: 2.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 7.1ms\n",
            "Speed: 2.6ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 tie, 7.2ms\n",
            "Speed: 4.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 15.9ms\n",
            "Speed: 3.3ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 laptop, 1 cell phone, 7.6ms\n",
            "Speed: 4.1ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 1 cell phone, 10.8ms\n",
            "Speed: 4.1ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 cell phone, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.5ms\n",
            "Speed: 2.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 toothbrush, 7.3ms\n",
            "Speed: 3.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.2ms\n",
            "Speed: 2.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 2 cell phones, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 2 cell phones, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 2 cell phones, 7.4ms\n",
            "Speed: 2.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 laptop, 2 cell phones, 7.5ms\n",
            "Speed: 2.7ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 2 cell phones, 1 book, 7.2ms\n",
            "Speed: 2.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 2 cell phones, 7.1ms\n",
            "Speed: 2.9ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 38.7ms\n",
            "Speed: 12.6ms preprocess, 38.7ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.9ms\n",
            "Speed: 3.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 9.4ms\n",
            "Speed: 5.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.3ms\n",
            "Speed: 2.6ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        }
      ],
      "source": [
        "# Install Ultralytics YOLOv8\n",
        "!pip install ultralytics\n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")  # Using YOLOv8 Nano model\n",
        "\n",
        "def run(img_str):\n",
        "    # Decode base64 image\n",
        "    decimg = base64.b64decode(img_str.split(',')[1], validate=True)\n",
        "    decimg = Image.open(BytesIO(decimg))\n",
        "    decimg = np.array(decimg, dtype=np.uint8)\n",
        "    decimg = cv2.cvtColor(decimg, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run YOLOv8 inference\n",
        "    results = model(decimg)\n",
        "\n",
        "    # Draw detections\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = box.conf[0].item()\n",
        "            cls = int(box.cls[0].item())\n",
        "            label = f\"{model.names[cls]} {conf:.2f}\"\n",
        "            cv2.rectangle(decimg, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(decimg, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Encode the processed image to base64\n",
        "    _, encimg = cv2.imencode(\".jpg\", decimg, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
        "    img_str = \"data:image/jpeg;base64,\" + base64.b64encode(encimg.tobytes()).decode('utf-8')\n",
        "    return IPython.display.JSON({'img_str': img_str})\n",
        "\n",
        "output.register_callback('notebook.run', run)\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "def use_cam(quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function useCam(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'None';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      display_size = 500;\n",
        "      const src_canvas = document.createElement('canvas');\n",
        "      src_canvas.width  = display_size;\n",
        "      src_canvas.height = display_size * video.videoHeight / video.videoWidth;\n",
        "      const src_canvasCtx = src_canvas.getContext('2d');\n",
        "      src_canvasCtx.translate(src_canvas.width, 0);\n",
        "      src_canvasCtx.scale(-1, 1);\n",
        "      div.appendChild(src_canvas);\n",
        "\n",
        "      const dst_canvas = document.createElement('canvas');\n",
        "      dst_canvas.width  = src_canvas.width;\n",
        "      dst_canvas.height = src_canvas.height;\n",
        "      const dst_canvasCtx = dst_canvas.getContext('2d');\n",
        "      div.appendChild(dst_canvas);\n",
        "\n",
        "      const btn_div = document.createElement('div');\n",
        "      document.body.appendChild(btn_div);\n",
        "      const exit_btn = document.createElement('button');\n",
        "      exit_btn.textContent = 'Exit';\n",
        "      var exit_flg = true;\n",
        "      exit_btn.onclick = function() { exit_flg = false };\n",
        "      btn_div.appendChild(exit_btn);\n",
        "\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      var send_flg = false;\n",
        "      async function _canvasUpdate() {\n",
        "        src_canvasCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight, 0, 0, src_canvas.width, src_canvas.height);\n",
        "        if (send_flg == false) {\n",
        "            send_flg = true;\n",
        "            const img = src_canvas.toDataURL('image/jpeg', quality);\n",
        "            const result = google.colab.kernel.invokeFunction('notebook.run', [img], {});\n",
        "            result.then(function(value) {\n",
        "                parse = JSON.parse(JSON.stringify(value))['data'];\n",
        "                parse = JSON.parse(JSON.stringify(parse))['application/json'];\n",
        "                parse = JSON.parse(JSON.stringify(parse))['img_str'];\n",
        "                var image = new Image();\n",
        "                image.src = parse;\n",
        "                image.onload = function() { dst_canvasCtx.drawImage(image, 0, 0); };\n",
        "                send_flg = false;\n",
        "            });\n",
        "        }\n",
        "        if (exit_flg) {\n",
        "            requestAnimationFrame(_canvasUpdate);\n",
        "        } else {\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "        }\n",
        "      }\n",
        "      _canvasUpdate();\n",
        "    }\n",
        "  ''')\n",
        "  display(js)\n",
        "  eval_js('useCam({})'.format(quality))\n",
        "\n",
        "use_cam()\n"
      ]
    }
  ]
}